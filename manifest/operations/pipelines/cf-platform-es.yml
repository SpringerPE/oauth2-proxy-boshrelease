- type: replace
  path: /instance_groups/name=logstash/properties/logstash/conf?/xpack.management.pipeline.id?/-
  value:
    "cf-platform-es"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env?/DST_HOSTS?
  value:
    "((es-host))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/ES_USER?
  value:
    "((es-user))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/ES_PASSWORD?
  value:
    "((es-password))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/ES_INDEX_PREFIX?
  value:
    "((es-index_prefix))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/CF_API?
  value:
    "((cf-api))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/SOURCE_ENV?
  value:
    "((source-env))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/env/SOURCE_PLATFORM?
  value:
    "((source-platform))"

- type: replace
  path: /instance_groups/name=logstash/properties/logstash/pipelines?
  value:
    - name: cf-platform-es
      config:
        filter-00-prefiltering: |
          ##-------------
          # Pre filtering
          ##-------------
          
          filter {
              mutate {
                  # Replace the unicode empty character \u0000 with ""
                  gsub => [ "message", '\u0000', ""]
          
                  # Trim excess whitespace
                  strip => [ "message" ]
              }
          
              # Drop empty useless logs
              if [message] =~ /^\s*$/ or [message] =~ /^#.*$/ {
                  drop { }
              }
          
              mutate {
                  rename => { "message" => "@message" }
          
                  # Add tags to track which job processed this event
                  add_field => {
                          "[@parser][job]" => "${JOB_FULL_AZ_DEPLOYMENT}"
                          "[@parser][instance]" => "${INSTANCE_ID}"
                          "[@parser][az]" => "${JOB_AZ}"
                          "[@parser][name]" => "${JOB_NAME}"
                          "[@parser][index]" => "${JOB_INDEX}"
                          "[@parser][deployment]" => "${DEPLOYMENT_NAME}"
                          "[@parser][lb-host]" => "%{host}"
                          "[@parser][lb-port]" => "%{port}"
                  }
          
                  # When behind LB, this is always the IP of the haproxy, not the IP of the actual host sending the data.
                  # Remove it to avoid confusion
                  remove_field => [ "host", "port" ]
              }
          }
          
        filter-10-syslog_rfc5424_parsing: |
          ##------------------------
          # standard rfc5424 parsing
          ##------------------------
          
          # NOTE: All parsed data should include @message, @level and @source.component.
          # Otherwise these fields are set from syslog_ fields in teardown script afterwards.
          
          filter {
              grok {
                  match => { "@message" => "%{POSINT:syslog_code} %{SYSLOG5424LINE}" }
                  add_tag => [ "syslog-5424" ]
                  add_field => {
                          "@type" => "log"
                          "@input" => "syslog"
                          "@raw" => "%{@message}"
                  }
                  tag_on_failure => ["fail/syslog-5424/grok"]
              }
          
              #                "@level" => "NONE"
          
              syslog_pri {
                  syslog_pri_field_name => "syslog5424_pri"
              }
          
              date {
                  match => [ "syslog5424_ts", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
                  timezone => "UTC"
                  remove_field => "syslog5424_ts"
              }
          
              mutate {
                  # '@message' should contain the remaining unparsed text
                  rename => { "syslog5424_msg" => "@message" }
                  add_field => {
                          "[@shipper][proto]" => "%{@input}"
                          "[@shipper][code]" => "%{syslog_code}"
                          "[@shipper][version]" => "%{syslog5424_ver}"
                          "[@shipper][facility]" => "%{syslog_facility_code}"
                          "[@shipper][priority]" => "%{syslog5424_pri}"
                          "[@shipper][severity]" => "%{syslog_severity_code}"
                          "[@shipper][name]" => "%{syslog5424_app}"
                          "[@shipper][type]" => "%{syslog5424_proc}"
                          "[@shipper][host]" => "%{[syslog5424_host]}"
          
                          "[@source][component]" => "%{syslog5424_app}"
                          "[@source][type]" => "%{syslog5424_proc}"
                          "[@source][env]" => "${SOURCE_ENV:cf}"
                          "[@source][host]" => "%{[syslog5424_host]}"
          
                          "@generator" => "%{[syslog5424_host]}"
                          "@instance"  => "-1"
                  }
              }
          
              # Extract instance metadata from structured data
              grok {
                  match => [ "syslog5424_sd", "\[%{DATA:syslog_sd_id} (?<syslog_sd_params_raw]>[^\]]+)\]" ]
                  remove_field => [
                      "syslog5424_sd"
                  ]
                  tag_on_failure => [ "fail/syslog-5424/sd/grok" ]
              }
              if !("fail/syslog-5424/sd/grok" in [tags]) {
                  # Convert the the key-value pairs
                  kv {
                      source => "syslog_sd_params_raw"
                      target => "syslog_sd_params"
                      remove_field => [
                          "syslog_sd_params_raw"
                      ]
                  }
          
                  # Syslog message with RFC 5424 and the enterprise number is CF
                  if [syslog_sd_id] == "instance@47450" {
                      mutate {
                          add_field => {
                              "[@source][az]" => "%{[syslog_sd_params][az]}"
                              "[@source][deployment]" => "%{[syslog_sd_params][deployment]}"
                              "[@source][director]" => "%{[syslog_sd_params][director]}"
                              "[@source][id]" => "%{[syslog_sd_params][id]}"
                              "[@source][job]" => "%{[syslog_sd_params][group]}"
                              "[@source][instance]" => "0"
                          }
                          replace => {
                              "@generator" => "%{[syslog_sd_params][group]}"
                              "[@source][type]" => "instance@47450"
                              "@type" => "cf"
                          }
                          add_tag => "47450"
                      }
                  }
                  # When an additional host is specified in the sd_params, promote syslog_hostname to @shipper.host
                  # and replace @source.host with sd_params.host
                  if [syslog_sd_params][host] {
                      mutate {
                          replace => {
                              "[@source][host]" => "%{[syslog_sd_params][host]}"
                          }
                      }
                  }
                  if [syslog_sd_params][instance] {
                      mutate {
                          replace => {
                              "@instance"  => "%{[syslog_sd_params][instance]}"
                              "[@source][instance]" "%{[syslog_sd_params][instance]}"
                          }
                      }
                      mutate {
                          convert => {
                              "[@source][instance]" => "integer"
                              "@instance" => "integer"
                          }
                      }
                  }
                  if [syslog_sd_params][type] {
                     # when the syslog params include a type, prepare the message for parsing by additional downstream parsing rules:
                     #  - Change the @type - this triggers downstream parsing rules
                     #  - @message_body = 'unparsed' message body that will be parsed by downstream @type rules
                     mutate {
                         replace => { "@type" => "%{syslog_sd_params[type]}" }
                     }
                  }
              }
          
              mutate {
                  lowercase => [ "[@source][type]", "[@source][component]" ]
                  convert => {
                      "[@shipper][version]" => "integer"
                      "[@shipper][facility]" => "integer"
                      "[@shipper][code]" => "integer"
                      "[@shipper][priority]" => "integer"
                      "[@shipper][severity]" => "integer"
                  }
                  remove_field => [ "syslog_code" ]
              }
          }
          
        filter-12-platform_sd_parsing: |
          ##-----------------------
          # Platform parsing not CF
          ##-----------------------
          
          filter {
              # Syslog message with RFC 5424 but enterprise number is not CF
              if (! [syslog_sd_id] or [syslog_sd_id] != "instance@47450") {
                  # Try parsing with possible CF formats
                  grok {
                      # Metron agent format (https://github.com/cloudfoundry/loggregator/blob/master/jobs/metron_agent/templates/syslog_forwarder.conf.erb#L53)
                      match => [ "@message", "\[job=%{NOTSPACE:[@source][job]} index=%{INT:[@source][index]:int}\]%{SPACE}%{GREEDYDATA:@message}" ]
                      # Syslog release format (https://github.com/cloudfoundry/syslog-release/blob/master/jobs/syslog_forwarder/templates/rsyslog.conf.erb#L56)
                      match => [ "@message", "\[bosh instance=%{NOTSPACE:[@source][deployment]}/%{NOTSPACE:[@source][job]}/%{NOTSPACE:[@source][job_index]}\]%{SPACE}%{GREEDYDATA:@message}" ]
                      overwrite => [ "@message" ]
                      tag_on_failure => "fail/cloudfoundry/platform/grok"
                  }
                  if !("fail/cloudfoundry/platform/grok" in [tags]) {
                      mutate {
                          replace => { "[@source][type]" => "cf" }
                          replace => { "@type" => "cf" }
                          add_tag => "cf"
                      }
                  }
              }
          }
          
        filter-20-set-metadata-index: |
          ##---------
          # Set index
          ##---------
          
          # @index_type stores type of index: app/platform
          # [@metadata][index] stores full index prefix (for app logs additionally includes org and space name)
          
          filter {
              # by default logs go to 'platform'
              mutate {
                  add_field => { "@index_type" => "platform" }
                  add_field => { "[@metadata][index]" => "%{@index_type}-%{[@source][deployment]}" }
                  lowercase => [ "[@metadata][index]" ]
              }
          }
          
        filter-61-platform_haproxy_parsing: |
          ##----------------------------------
          # Haproxy conf. Parses haproxy logs.|
          ##----------------------------------
          
          filter {
              if [@source][component] == "haproxy" {
                  mutate {
                    replace => { "@type" => "haproxy" }
                    add_tag => "haproxy"
                  }
                  # Grok patterns are based on http://www.haproxy.org/download/1.7/doc/configuration.txt
                  # Two formats are used accordingly:
                  # 8.2.3. HTTP log format
                  # 8.2.5. Error log format
                  grok {
                    match => [ "@message", "%{IP:[haproxy][client_ip]}:%{INT:[haproxy][client_port]:int} \[%{DATA:[haproxy][accept_date]}\] %{NOTSPACE:[haproxy][frontend_name]} %{NOTSPACE:[haproxy][backend_name]}/%{NOTSPACE:[haproxy][server_name]} %{INT:[haproxy][time_request]:int}/%{INT:[haproxy][time_queue]:int}/%{INT:[haproxy][time_backend_connect]:int}/%{INT:[haproxy][time_backend_response]:int}/%{INT:[haproxy][time_duration]:int} %{INT:[haproxy][http_status_code]:int} %{NOTSPACE:[haproxy][bytes_read]:int} %{DATA:[haproxy][captured_request_cookie]} %{DATA:[haproxy][captured_response_cookie]} %{NOTSPACE:[haproxy][termination_state]} %{INT:[haproxy][actconn]:int}/%{INT:[haproxy][feconn]:int}/%{INT:[haproxy][beconn]:int}/%{INT:[haproxy][srvconn]:int}/%{NOTSPACE:[haproxy][retries]:int} %{INT:[haproxy][srv_queue]:int}/%{INT:[haproxy][backend_queue]:int} (\{%{DATA:[haproxy][captured_request_headers]}\})?( )?(\{%{DATA:[haproxy][captured_response_headers]}\})?( )?\"(?<message>(?<haproxy_http_request>(<BADREQ>|((%{WORD:[haproxy][http_request_verb]})?( %{GREEDYDATA})?))))\"" ]
                    match => [ "@message", "%{IP:[haproxy][client_ip]}:%{INT:[haproxy][client_port]:int} \[%{DATA:[haproxy][accept_date]}\] %{NOTSPACE:[haproxy][frontend_name]}/%{NOTSPACE:[haproxy][bind_name]}:%{SPACE}%{GREEDYDATA:message}" ]
                    tag_on_failure => "fail/cloudfoundry/platform-haproxy/grok"
                  }
                  if !("fail/cloudfoundry/platform-haproxy/grok" in [tags]) {
                      if [haproxy_http_request] {
                          mutate {
                            rename => {"haproxy_http_request" => "[haproxy][http_request]"}
                          }
                      }
                      mutate {
                        rename => {"message" => "@message"} # @message
                      }
                      # @level
                      if [haproxy][http_status_code] {
                          if [haproxy][http_status_code] >= 400 {
                              mutate {
                                add_field => { "@level" => "ERROR" }
                              }
                          } else {
                              mutate {
                                add_field => { "@level" => "INFO" }
                              }
                          }
                      }
                  }
              }
          }
        filter-62-platform_uaa_parsing: |
          ##-------------------------
          # Uaa conf. Parses uaa logs
          ##-------------------------
          
          filter {
              if [@source][component] == "vcap.uaa" {
                  mutate {
                    # remove vcap. prefix
                    replace => { "[@source][component]" => "uaa" }
                    replace => { "@type" => "uaa" }
                    add_tag => "uaa"
                  }
                  grok {
                    match => { "@message" => "\[%{TIMESTAMP_ISO8601:[uaa][timestamp]}\]%{SPACE}uaa%{SPACE}-%{SPACE}%{NUMBER:[uaa][pid]:int}%{SPACE}\[%{DATA:[uaa][thread]}\]%{SPACE}....%{SPACE}%{LOGLEVEL:@level}%{SPACE}---%{SPACE}%{DATA:[uaa][log_category]}:%{SPACE}%{GREEDYDATA:@message}"}
                    overwrite => ["@message", "@level"] # @message, @level
                    tag_on_failure => "fail/cloudfoundry/platform-uaa/grok"
                  }
                  if [uaa][log_category] == "Audit" {
                      mutate {
                        replace => { "@type" => "uaa-audit" }
                        add_tag => "audit"
                      }
                      # ---- Additional parsing: Audit events
                      grok {
                        match => { "@message" => "(?<uaa_audit_message>(%{WORD:[uaa][audit][type]}%{SPACE}\('%{DATA:[uaa][audit][data]}'\))):%{SPACE}principal=%{DATA:[uaa][audit][principal]},%{SPACE}origin=\[%{DATA:[uaa][audit][origin]}\],%{SPACE}identityZoneId=\[%{DATA:[uaa][audit][identity_zone_id]}\]"}
                        tag_on_failure => "fail/cloudfoundry/platform-uaa/audit/grok"
                      }
                      if !("fail/cloudfoundry/platform-uaa/audit/grok" in [tags]) {
                          # Audit @message
                          mutate {
                            rename => { "uaa_audit_message" => "@message" }
                          }
                          # extract audit_event_remote_address and geoip it
                          if "PrincipalAuthenticationFailure" == [uaa][audit][type] {
                              mutate {
                                add_field => { "[uaa][audit][remote_address]" => "%{[uaa][audit][origin]}" }
                              }
                          }
                          if [uaa][audit][origin] =~ /remoteAddress=/ {
                              grok {
                                match => { "[uaa][audit][origin]" => "remoteAddress=%{IP:[uaa][audit][remote_address]}" }
                              }
                          }
                          if [uaa][audit][remote_address] {
                             geoip {
                               source => "[uaa][audit][remote_address]"
                             }
                          }
                          # split origin
                          mutate {
                            split =>  { "[uaa][audit][origin]" => ", " }
                          }
                      }
                  }
              }
          }
        filter-63-platform_vcap_and_json_parsing: |
          ##------------------------------------------
          # Vcap conf. Parses vcap* logs. (after UAA!)
          ##------------------------------------------
          
          filter {
              if [@source][component] =~ /vcap\..*/ {
                  # minus vcap. prefix
                  mutate {
                    gsub => ["[@source][component]", "^vcap\.", ""]
                  }
                  mutate {
                    replace => { "@type" => "vcap" }
                    add_tag => "vcap"
                  }
                  # Parse Cloud Foundry logs
                  if [@message] =~ /^\s*{".*}\s*$/ { # looks like JSON
                      # parse JSON message
                      json {
                        source => "@message"
                        target => "parsed_json_field"
                        remove_field => [ "@message" ]
                        add_field => { "parsed_json_field_name" => "%{[@source][component]}"}
                      }
                      if "_jsonparsefailure" in [tags] {
                          # Amend the failure tag to match our fail/${addon}/${filter}/${detail} standard
                          mutate {
                            add_tag => ["fail/cloudfoundry/platform-vcap/json"]
                            remove_tag => ["_jsonparsefailure"]
                          }
                      } else {
                          mutate {
                            rename => { "[parsed_json_field][message]" => "@message" } # @message
                          }
                          # @level
                          translate {
                            field => "[parsed_json_field][log_level]"
                            dictionary => [ "0", "DEBUG", "1", "INFO", "2", "ERROR", "3", "FATAL" ]
                            destination => "@level"
                            override => true
                            fallback => "%{[parsed_json_field][log_level]}"
                            remove_field => "[parsed_json_field][log_level]"
                          }
                      }
                  }
              }
          }
        filter-90-set_syslog_level: |
          ##-------------------
          # define syslog level
          ##-------------------
          
          # Apply default settings for mandatory fields (if not set)
          
          filter {
              # set syslog @level (if @level is not set yet)
              if ![@level] and [syslog_severity_code] {
                  if [syslog_severity_code] <= 3 {                      # 0-Emergency, 1-Alert, 2-Critical, 3-Error
                      mutate {
                          add_field => { "@level" => "ERROR" }
                      }
                  } else if [syslog_severity_code] <= 5 {               # 4-Warning, 5-Notice
                      mutate {
                          add_field => { "@level" => "WARN" }
                      }
                  } else if [syslog_severity_code] == 6 {               # 6-Informational
                      mutate {
                          add_field => { "@level" => "INFO" }
                      }
                  } else if [syslog_severity_code] == 7 {               # 7-Debug
                      mutate {
                          add_field => { "@level" => "DEBUG" }
                      }
                  }
              }
          
              mutate {
                  uppercase => [ "@level" ]
              }
          }
        filter-91-rework_fields: |
          ##-------------
          # Rework fields
          ##-------------
          
          filter{
              if [@source][job] and [@source][index] {
                  mutate {
                      add_field => { "[@source][vm]" => "%{[@source][job]}/%{[@source][index]}" }
                  }
              }
          
              if ![@source][host] {
                  mutate { rename => { "[host]" => "[@source][host]" } }
              }
          
              # Downcase [parsed_json_field_name] and replace special characters with '_')..
              # .. and rename dynamic [parsed_json_field] field to this calculated name.
          
              if [parsed_json_field] and [parsed_json_field_name] {
                  mutate {
                      lowercase => [ "parsed_json_field_name" ]
                      gsub => [ "parsed_json_field_name", "[\s/\\?#-\.]", "_" ]
                  }
                  mutate {
                      rename => { "parsed_json_field" => "%{parsed_json_field_name}" }
                  }
              }
          
              mutate {
                  remove_field => [ "parsed_json_field_name" ]
              }
          }
        filter-99-cleanup: |
          ##--------------------------
          # Cleanup unnecessary fields
          ##--------------------------
          
          filter {
              mutate {
                  # Remove syslog_ fields
                  remove_field => "syslog5424_pri"
                  remove_field => "syslog5424_ts"
                  remove_field => "syslog5424_host"
                  remove_field => "syslog5424_ver"
                  remove_field => "syslog5424_app"
                  remove_field => "syslog5424_proc"
                  remove_field => "syslog_sd_params"
                  remove_field => "syslog_facility"
                  remove_field => "syslog_facility_code"
                  remove_field => "syslog_severity"
                  remove_field => "syslog_severity_code"
          
                  # Cleanup
                  remove_field => "@version"
                  remove_field => "host"
                  remove_field => "port"
                  remove_field => "_logstash_input"
              }
          }
          
        input-10-syslog: |
          input {
              tcp {
                add_field => [ "type", "syslog" ]
                id => "input-syslog/${JOB_FULL_AZ_DEPLOYMENT}"
                port => "5514"
              }
              #syslog {
              #    port => 5514
              #    use_labels => true
              #    type => "syslog"
              #    tags => []
              #    add_field => { "_index_name" => "syslog" }
              #}
          }
          
        output-10-es: |
          output {
            elasticsearch {
              hosts => [ "${ES_HOSTS}" ]
              user => "${ES_USER}"
              password => "${ES_PASSWORD}"
              sniffing => false
              index => "${ES_INDEX_PREFIX:logs}-%{[@metadata][index]}-%{+YYYY.MM.dd}"
              http_compression => true
              manage_template => false
              id => "output-es/${JOB_FULL_AZ_DEPLOYMENT}"
            }
            # stdout { codec => rubydebug }
          }
